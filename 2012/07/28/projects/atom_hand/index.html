<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>凌动的“奇”手 --仿生机械手 | Xiongmin Lin</title>

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <meta name="description" content="摘要 本系统主要以 EPCM-505C 开发平台为核心,利用虚拟现实与视觉技术,借助 Intel AtomTME645C 处理器,FPGA 及 Intel IPP、OpenMP、OpenNI、OpenCV、RTP 视频传输协议,旨在代替人完成轻量级的危险任务。该系统采用服务器、客户端架构模式。其中,服务器平台负责采集用户的手臂动作信息,客户端平台负责现场视频的采集传输以及仿生机械手臂的控制。客户端">
<meta name="keywords" content="Embedded system programming - Kinect &amp; OpenNI - Network">
<meta property="og:type" content="article">
<meta property="og:title" content="凌动的“奇”手 --仿生机械手">
<meta property="og:url" content="http://linxiongmin.com/2012/07/28/projects/atom_hand/index.html">
<meta property="og:site_name" content="Xiongmin Lin">
<meta property="og:description" content="摘要 本系统主要以 EPCM-505C 开发平台为核心,利用虚拟现实与视觉技术,借助 Intel AtomTME645C 处理器,FPGA 及 Intel IPP、OpenMP、OpenNI、OpenCV、RTP 视频传输协议,旨在代替人完成轻量级的危险任务。该系统采用服务器、客户端架构模式。其中,服务器平台负责采集用户的手臂动作信息,客户端平台负责现场视频的采集传输以及仿生机械手臂的控制。客户端">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/690aa174gw1eufjkp2iymj20ni0dqq43.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/690aa174gw1eufjnuuugoj20m20v7afe.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/690aa174gw1eufjucdl2dj20gv09d3zg.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/690aa174gw1eufjxdikyxj20a5068dfx.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/690aa174gw1eufjyfnagij208u04r3yi.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/690aa174gw1eufjznpqb7j209604y0ss.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/690aa174gw1eufk3klf36j20tk0b4mxm.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/690aa174gw1eufkdddmdzj20hi083q3k.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/690aa174gw1eufkhajzh7j20lk0omtd7.jpg">
<meta property="og:updated_time" content="2015-07-25T18:13:38.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="凌动的“奇”手 --仿生机械手">
<meta name="twitter:description" content="摘要 本系统主要以 EPCM-505C 开发平台为核心,利用虚拟现实与视觉技术,借助 Intel AtomTME645C 处理器,FPGA 及 Intel IPP、OpenMP、OpenNI、OpenCV、RTP 视频传输协议,旨在代替人完成轻量级的危险任务。该系统采用服务器、客户端架构模式。其中,服务器平台负责采集用户的手臂动作信息,客户端平台负责现场视频的采集传输以及仿生机械手臂的控制。客户端">
<meta name="twitter:image" content="http://ww1.sinaimg.cn/large/690aa174gw1eufjkp2iymj20ni0dqq43.jpg">

  
    <link rel="alternate" href="/atom.xml" title="Xiongmin Lin" type="application/atom+xml">
  

  
  <!--[if lte IE 10 ]><link rel="shortcut icon" href="/images/favicon.ico"><![endif]-->
  <!--[if !IE]><!-->
  <link rel="shortcut icon" href="/images/favicon.png">

  <meta name="msapplication-TileImage" content="/images/favicon.png">
  <meta name="msapplication-TileColor" content="#000000">

  <link rel="apple-touch-icon" href="/images/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/images/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/images/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/images/apple-touch-icon-144x144.png">

  <link rel="icon" sizes="256x256" href="/images/favicon.png">
  <!--<![endif]-->
  

  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro|Material+Icons|Raleway:400,300,700" rel="stylesheet" type="text/css">

  <link rel="stylesheet" href="/css/vendors.css">
  <link rel="stylesheet" href="/css/style.css">
  


  <script src="/js/vendors.js"></script>

  <script>
    define('jquery', function () {
      return window.jQuery;
    });
  </script>


</head>
<body>

  <div class="navbar-fixed">
  <nav id="main-navbar" class="grey lighten-5 z-depth-0" role="navigation">
    <div class="nav-wrapper container">

      <a id="logo-container" href="/" class="brand-logo center-align">
        <span>Xiongmin Lin</span>
        <sub></sub>
      </a>

      <ul class="right hide-on-med-and-down">
        
          <li>
            <a class="main-nav-link" href="/">Home</a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/blog">Blog</a>
          </li>
        
          <li>
            <a class="main-nav-link" href="https://www.linkedin.com/in/shelmylin">Linkedin</a>
          </li>
        
      </ul>

      <a href="#" data-activates="nav-mobile" class="button-collapse">
        <i class="material-icons">menu</i>
      </a>
    </div>
  </nav>
</div>

<ul id="nav-mobile" class="side-nav">
  
  <li>
    <a class="main-nav-link" href="/">Home</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/blog">Blog</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="https://www.linkedin.com/in/shelmylin">Linkedin</a>
  </li>
  
</ul>


  <div id="main-container">
    
<div class="container">
  <div class="row">
    <div class="col s12">


      <article id="post-projects/atom_hand" class="article article-type-post" itemscope="" itemprop="blogPost">

        <div class="article-inner">
          

          <header class="article-header">
          
              
  
    <h1 class="article-title header" itemprop="name">
      凌动的“奇”手 --仿生机械手
    </h1>
  


          

            <div class="article-meta">
              <i class="fa fa-calendar"></i>
              <time datetime="2012-07-29T01:20:00.000Z" itemprop="datePublished">Jul 28, 2012</time>
            </div>
          </header>


          <div class="article-entry " itemprop="articleBody">
            
              <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><blockquote>
<p>本系统主要以 EPCM-505C 开发平台为核心,利用虚拟现实与视觉技术,借助 Intel AtomTME645C 处理器,FPGA 及 Intel IPP、OpenMP、OpenNI、OpenCV、RTP 视频传输协议,旨在代替人完成轻量级的危险任务。该系统采用服务器、客户端架构模式。其中,服务器平台负责采集用户的手臂动作信息,客户端平台负责现场视频的采集传输以及仿生机械手臂的控制。客户端平台装于遥控小车上,程序启动,客户端平台开始采集、传回现场视频,并在客户端的屏幕上显示小车周遭场景。位于服务器端的用户根据传回的视频控制小车躲避障碍物进去危险区域后,首先通过安置在终端的体态传感器获取人体的手臂运动姿态并实时传输给客户端平台,然后由平台cpu 通过 PCIE 将捕获的数据传至 FPGA,再由 FPGA 控制仿生机械臂的运动,使得机械臂远程完成与人体手臂相同的动作,从而达到远程遥控机械臂完成轻量级任务的目的。</p>
</blockquote>
<blockquote>
<ul>
<li>关键词 :仿生机械臂,远程体态控制, RTP 无线视频通信</li>
</ul>
</blockquote>
<h1 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h1><h2 id="系统方案"><a href="#系统方案" class="headerlink" title="系统方案"></a>系统方案</h2><p>系统采用 C/S 模式,由服务器端和客户端组成。其中客户端基于以 Intel Atom E645C处理器为核心的嵌入式系统,包括装载在遥控车上的机械臂和电源系统,并外扩了摄像头。服务器端包括采集用户信息的体态传感器及视频显示终端。客户端通过无线网络将视频传输给服务器端,在服务器端接收显示。同时,服务器端远程控制客户端仿生机械手完成轻量级的替代人工作业的任务。</p>
<p><img src="http://ww1.sinaimg.cn/large/690aa174gw1eufjkp2iymj20ni0dqq43.jpg" alt="系统方案"></p>
<p>系统工作流程分为如下几个部分:</p>
<ul>
<li>远程服务器端启动,客户端 EPCM-505C 启动,安装在小车上的摄像头开始工作。</li>
<li>服务器开始接受客户端通过无线网络传回的视频并显示在软件窗口。</li>
<li>用户根据显示的视频,得到路况信息,遥控小车进入工作区域。</li>
<li>小车进入工作位置完毕,用户站于体态传感器前,通过服务器识别认证,获得机械手臂的控制权。</li>
<li>用户根据小车传回的视频,控制机械手臂完成任务。</li>
<li>任务完毕之后,用户停止对机械手臂的控制,小车收起机械手臂,用户遥控小车返回。</li>
</ul>
<h2 id="软件流程图"><a href="#软件流程图" class="headerlink" title="软件流程图"></a>软件流程图</h2><p>系统软件流程分作两个部分:仿生机械手臂控制流程和视频采集传输流程<br><img src="http://ww1.sinaimg.cn/large/690aa174gw1eufjnuuugoj20m20v7afe.jpg" alt="系统软件流程图"></p>
<h3 id="仿生机械手臂控制流程"><a href="#仿生机械手臂控制流程" class="headerlink" title="仿生机械手臂控制流程"></a>仿生机械手臂控制流程</h3><p>OpenNI,OpenCV 一些常规变量进行了定义与初始化,为后面程序的执行做好基础。当 RTP 初始化完成后,体态传感器开始工作,软件提示框提示用户举起双手做出“校验”姿势,进行用户识别,当用户识别成功之后,体态传感器开始源源不断的更新数据。</p>
<p>体态传感器捕获到用户骨骼坐标,通过“骨骼坐标采集算法”得到用户右手手腕,肘关节以及肩关节的三维坐标。由于体态传感器采集到的数据存在抖动现象,我们将采集到的骨骼坐标经过“骨骼防抖动算法”滤波,得到平滑变化的骨骼数据。<br>体态传感器成功采集到平滑的骨骼数据之后,“手臂移动角度采集算法”开始对骨骼数据进行处理,将手臂骨骼移动的信息提取为四个角度的变化,同时,“手掌握合检测算法”开始采集手掌握合的信息,然后再将这些信息提取为第五个角度的变化,因为提取到的角度也存在抖动现象,类似“骨骼防抖动算法”一样,我们也加入了“角度防抖动算法”,使最后得到的角度值不会突变过大。</p>
<p>在服务器端得到了手臂移动的五个角度值后,程序对这五个角度进行打包处理,加入校验信息,然后使用 rtp 协议对其进行传输,客户端 EPCM-505C 同步接收到含有角度信息的数据包并且校验成功后,CPU 会将这些数据发送给 FPGA 处理。FPGA 在得到这些角度信息之后,通过“获取多路 PWM 波算法”,产生五路包含角度信息的 PWM 波,五路舵机在 PWM 波的驱动下,转动相应的角度值,即机械手臂开始工作,在同一时刻完成与用户相同的动作。</p>
<h3 id="视频采集传输流程"><a href="#视频采集传输流程" class="headerlink" title="视频采集传输流程"></a>视频采集传输流程</h3><p>客户端程序启动,开始对 OpenCV 及 RTP 协议做必要的初始化,然后尝试连接服务器。每个 RPT 服务都需要客户端及服务器端提供 IP 地址及两个传输端口(一个发送,一个接受),程序会根据这些信息,建立连接 RTP 连接。服务器连接成功之后,客户端视频采集程序启动,通过 OpenCV 捕获视频流,然后获取一帧图像,并且打包成数据包供给 RTP 传输,我们“视频采集传输算法”就是完成这些工作的。</p>
<h2 id="系统核心算法"><a href="#系统核心算法" class="headerlink" title="系统核心算法"></a>系统核心算法</h2><h3 id="骨骼坐标的采集与滤波"><a href="#骨骼坐标的采集与滤波" class="headerlink" title="骨骼坐标的采集与滤波"></a>骨骼坐标的采集与滤波</h3><p>用户骨骼坐标主要是通过我们自己写的whu_MyHand类的成员函数whu_GetSkeleton来获取的,whu_GetSkeleton有三个参数:m_RHand,m_RElbow ,m_RShoulder,分别代表右手手腕,右手肘关节及右肩关节的三维坐标。<br>程序初始化完成之后, OpenNI开始检测当前可视区域是否存在用户,区域内出现用户的时候,用户会被体态传感器一直跟踪,如果有多个用户,OpenNI还会为每个用户添加编号以识别不同的用户。<br>OpenNI检测出用户之后,开始检测用户是否做出“校验”姿势,所谓的“校验”姿势,即用户双手举过头,作投降状。</p>
<p><img src="http://ww2.sinaimg.cn/large/690aa174gw1eufjucdl2dj20gv09d3zg.jpg" alt=""></p>
<p>当用户做出“校验”动作并且被OpenNI成功检测出来的时候,生产链路开始工作, OpenNI函数GetSkeletonCap开始捕获用户的骨骼信息。实验发现,通过体态传感器直接采集到的骨骼信息存在抖动现象,因此还需要对这些骨骼信息进行防抖动滤波处理,我们设置了一个骨骼瞬时变化的最大距离圆,新的骨骼坐标与旧的骨骼坐标进行比较,当新的骨骼点落在距离圆里面的时候,说明骨骼数据没有抖动,反之,则说明骨骼存在抖动,我们就将新的骨骼点设置为这两个骨骼点连线的中点值。whu_GetSkeleton函数已经将骨骼坐标采集算法和滤波算法封装了,调用whu_GetSkeleton,函数将返回平滑的骨骼坐标值。</p>
<h3 id="手臂移动角度的采集与滤波"><a href="#手臂移动角度的采集与滤波" class="headerlink" title="手臂移动角度的采集与滤波"></a>手臂移动角度的采集与滤波</h3><p>通过上面的算法,我们已经得到了所需要的骨骼坐标,用户手臂摆动的时候,其骨骼坐标也会跟着变化,接下来,我们将这些变化的坐标转化成角度。</p>
<p>角度的获取主要是通过whu_MyHand类的成员函数whu_GetAngles实现的,用户摆动手臂的动作,可以分解为左右,前后,上下 三个方向的运动,手臂的左右摆动,我们是通过右手肩关节与腕关节的三维坐标的变化获取的,胳膊的前后摆动,主要反映到腕关节相对肘关节的坐标的变化,小臂的上下移动,可以视为腕关节与肘关节坐标的变化,手臂在这三个自由度的运动,可以直接对应三自由度舵机的转动。</p>
<p>手臂左右摆动:具体是由右手肩关节与腕关节的三维坐标获取的,如图所示,当用户正对着体态传感器做出左右移动手臂的动作的时候,腕关节的X与Z坐标的变化度是最大的,而肩关节几乎没有变化。当手腕从位置1变化到位置3时,对应的角度从角度1增到到角度3,由肩关节与腕关节的XZ坐标,很容易得到手臂左右摆动的角度。</p>
<p><img src="http://ww2.sinaimg.cn/large/690aa174gw1eufjxdikyxj20a5068dfx.jpg" alt="手臂左右摆动"></p>
<p>胳膊的前后变动:由下图人胳膊前后的变动主要反映到肘关节坐标的变动。根据实际反复的实验结果,当轴关节的 Z 坐标大于肩关节时,角度一律取 60 度,反之,为了保持角度变化的平滑性,在 60 度的基础再加上图中角度。<br><img src="http://ww4.sinaimg.cn/large/690aa174gw1eufjyfnagij208u04r3yi.jpg" alt="胳膊的前后变动"></p>
<p>小臂的前后摆动:由下图小臂前后摆动的变化主要反映到腕关节相对肘关节的坐标的变化,当腕关节的位置前于肘关节(即腕关节的 Z 值小于肘关节)时,角度 1 和 2 分别为腕关节位于位置 1 和 2 时的转角,而当腕关节的位置后于肘关节时(如位置 3),为了保持角度的平滑变化,需在角度 3 的基础上加上 90 度。</p>
<p><img src="http://ww1.sinaimg.cn/large/690aa174gw1eufjznpqb7j209604y0ss.jpg" alt="小臂的前后摆动"></p>
<p>以上考虑的是胳膊不动的时候小臂变化的角度,实际上,用户在完成一个手臂动作的时候,胳膊和小臂是一起移动的,因此,为了得到单纯的小臂移动角度,还得消除胳膊移动带来的影响,经反复实验,我们为小臂的摆动增加了修正值。</p>
<h3 id="手掌握合检测算法"><a href="#手掌握合检测算法" class="headerlink" title="手掌握合检测算法"></a>手掌握合检测算法</h3><p>由于体态传感器没办法直接捕获到手指的坐标,我们通过上面提到过的whu_MyHand类的<br>成员函数whu_GetFingerAngle来得到手掌张合,具体算法如下:</p>
<ul>
<li>通过 OpenNI得到用户的深度资料图,然后将深度图通过平滑算法而后二值化为灰度图,并根据最小的Z值(即指尖的位置)得到手掌区域部分。</li>
<li>将手掌部分的灰度图转化成一个2D矩阵的点集合,由于手掌张开的时候存在凹凸点会有夹角,因此,我们以3个点一组,判定旁边两个点与中间点的连线的夹角值,当夹角小于某个阈值的时候,便可以判定旁边中间点位于指尖位置,而当手掌张开的时候,会有很多个这样的点(平均每次可检测到32个点),这些点大部分都是位于指尖位置和手掌凹陷位置,排除那些离掌心很近的点(即手掌凹陷点),可以得到手指指尖点,如图4.2.6,红点为检测到的指尖位置, 而当手掌握合的时候,点数很少(平局每次检测到1个点)如图4.2.7示。</li>
</ul>
<p><img src="http://ww3.sinaimg.cn/large/690aa174gw1eufk3klf36j20tk0b4mxm.jpg" alt=""></p>
<h3 id="视频的采集传输"><a href="#视频的采集传输" class="headerlink" title="视频的采集传输"></a>视频的采集传输</h3><p>本系统的视频传输功能的实现采用的是实时传输协议(Real-time Transport Protocol,RTP)。RTP 是在 Internet 上处理多媒体数据流的一种网络协议,它是目前解决流媒体实时传输问题的最好办法。利用它能够在一对一(unicas,单播)或者一对多(multicas,多播)的网络环境中实现传流媒体数据的实时传输。</p>
<h3 id="仿生机械臂的控制"><a href="#仿生机械臂的控制" class="headerlink" title="仿生机械臂的控制"></a>仿生机械臂的控制</h3><p>从服务器端采集到的五路角度信息会通过RTP远程传输至位于客户端平台，并通过PWM波转换，得到五个舵机相应的转角。舵机控制线的输入是一个宽度可调的周期性方波脉冲信号,方波脉冲信号的周期为 20ms (即频率为 50 Hz)。当方波的脉冲宽度改变时,舵机转轴的角度发生改变,角度变化与脉冲宽度的变化成正比,其利用占空比来控制舵机的位置。<br>由舵机的工作原理可知,给舵机输入一个周期在 20ms 左右,脉冲宽度在 0.5ms 至 2.5ms之间的周期性脉冲信号,驱动舵机输出轴达到-90°到 90°之间的转角,呈线性变化。并且无论外界转矩怎样改变,舵机的输出轴都会保持在一个相对应的角度上,直到给它提供一个另外宽度的脉冲信号,才会改变输出角度到新的对应的位置上。因此,我们可以通过编程在FPGA 的输出端口得到需要的周期性脉冲信号。</p>
<p><img src="http://ww2.sinaimg.cn/large/690aa174gw1eufkdddmdzj20hi083q3k.jpg" alt="FPGA控制机械臂的流程图"></p>
<h2 id="系统结果"><a href="#系统结果" class="headerlink" title="系统结果"></a>系统结果</h2><p><img src="http://ww3.sinaimg.cn/large/690aa174gw1eufkhajzh7j20lk0omtd7.jpg" alt=""><br>机械手臂在用户控制下完成抓取动作杯子并放下的动作</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 刘金国,王越超,李斌. 灾难救援机器人研究现状、关键性能及展望.[J].机械工程学报,2012,42(12):1-9.<br>[2] 罗元,谢彧,张毅,等. 基于Kinect传感器的智能轮椅手势控制系统的设计与实现.[J].机器人,2012,34(1):110-119.<br>[3] 姜永成,周正干,任福君,等. 基于OpenCV的移动机器人视频流采集与处理.[J].机床与液压,2010,38(15):40-43.<br>[4] 黎松,平西建,丁益洪,等. 开放源代码的计算机视觉类库OpenCv的应用.[J].计算机应用与软件, 2005,22(8):134-136.<br>[5] 郑晓曦,刘维. 基于DirectShow 的无线音视频采集与传输系统的研究.[J]. 数字技术与应用,2011(12).<br>[6] 陈勇,陈国良,李春生. SMP机群混合编程模型研究.[J].小型微型计算机系统,2004,25(10):1763-1767.<br>[7] 漆旺生,朱锴,李建堂. 如何当好抢险救灾总指挥.[J].1998(05).<br>[8] 李克杰. 危险作业机器人发展战略研究.[J].机器人技术与应用, 2003(05).<br>[9] 李磊,叶涛,谭民. 移动机器人技术研究现状与未来.[J]. 机器人,2002(05).<br>[10] 戴先中. 危险作业机器人–人类的好帮手[J].机器人技术与应用, 2003(03).<br>[11] 张福学. 机器人技术及其应用[J]. 2000.<br>[12] 寒芯. 日本消防机器人.[J]. 1996(03).<br>[13] 李金良,包继华,于岩,等. 救援机器人自适应模糊控制的研究.[J].计算机测量与控制, 2010,5.<br>[14] 李金良,孙友霞,包继华,等. 救援机器人目标跟踪控制的研究.[J].工矿自动化,2009,12.<br>[15] 刘先灿,基于构型选优的多冗余机器人理论及实验的研究.[D].2010.<br>[16] 戴剑文.吴波救灾机器机器机器人人性化的救助装备.[J].工业设计,2011(1).<br>[17] 郭瑞璜,Guo Ruihuang. 日本新一代救援机器人——T-53 援龙.[J].消防技术与产品信息 2011(4).<br>[18] 钱善华,葛世荣. 救灾机器人的研究现状与煤矿救灾的应用.[J].机器人,2006(05).<br>[19] 李斌蛇. 形机器人的研究及在灾难救援中的应用.[J].机器人技术与应用,2003(03).<br>[20] 杨璐. 浅谈视频监控系统的技术特点及其应用.[J]. 安防科技,2008(6).<br>[21] 杨领军. 数字图像传 输中的 比特率 控制.[J].北京广播学院 学报(自然 科学版),2001(4).<br>[22] 宋军,顾冠群. 多媒体通信媒体间同步技术综述.[J]. 电信科学;1996(9).<br>[23] 李国辉,许健,汤大权. 多媒体音频视频对象的同步技术研究.[J].计算机研究与发展,1995(4).<br>[24] 崔莉,王敏,吉逸. 流媒体同步机制的研究.[J]. 计算机应用研究,2005(9).<br>[25] 张文琴, 浅析流媒体数据压缩标准.[J]. 电脑知识与技术,2010(14).<br>[26] 石峻,余松煜. Windows 环境下的实时视频捕获技术.[J]. 计算机工程,1999(8).35凌动的“奇”手<br>[27] S C HUI,F WANG. Remote Video Monitoring Over the WWW.[J].2003.<br>[28] 韩秋凤,肖政宏. 嵌入式远程视频监控系统的设计与实现.[J].湖南文理学院学报(自然科学版),2005,3.<br>[29] 申华. 基于 Windows 环境下视频捕获技术的研究及应用.[D].2005.<br>[30] 徐大诚,邵雷,李培光,等. 基于USB2.0的数字图像视频流的实时捕捉与显示系统的设计与实现.[J]. 计算机应用与软件,2008,25(9).<br>[31] 邓红卫,DENG Hong-wei. DirectShow和WinSock在网络视频系统中的应用.[J].计算机与现代化,2005(3).<br>[32] 郑桦. 机械臂系统的网络远程控制研究与实现[D].合肥,中国科学技术大学,2007.<br>[33] 张君鸿,马玉林. 基于Internet的远程机器人控制时间延迟的研究.[J].黑龙江:哈尔滨铁道科技,2003(3).<br>[34] 刘富强.数字视频信息处理与传输教程.[M]. 第l版.北京:机械工业出版社, 2004(3).<br>[35] 谢洪胜,毛迪林,黄晓霖. RTP和TCP在实时传输中的比较.[J].微型电脑应用, 2000(16).<br>[36] 李尚军.基于机械臂的远程视频监控系统研究[D].西安:西安电子科技大学,2009.<br>[37] 王庆鹏,谈大龙,陈宁.基于Intemet的机器人控制中网络时延测试及分析[J].机器人,2001,23(4).<br>[38] 冯兰胜.基于机械臂的远程控制系统研究[D].西安:西安电子科技大学,2005.<br>[39] 汪地.机器人远程监控系统的研究[D].上海:上海大学,2005.<br>[40] 郑桦,丛爽,魏子翔.基于网络机械臂远程控制系统延时补偿的研究与实现[J].北京:中国科学院研究生院学报,2007(7).<br>[41] 杨克洪,马旭东.移动机器人远程监控系统的实时性改进[J].工业控制计算机, 2007,20(1).<br>[43] 史胜利. 基于Internct的机器人遥操作系统关键技术研究[D].哈尔滨:哈尔滨工程大学,2004.<br>[43] Santosh Iyer. Using Kinect Sensor and OpenNI to teach Human computer Interactionand Natural User Interfaces.[J]. International Journal of Computer Applications2012, icwet(11).</p>

            
          </div>

          

          <footer class="article-footer">
            <a data-url="http://linxiongmin.com/2012/07/28/projects/atom_hand/" data-id="cjpf4cha8001gbh4zlpmgg76h" class="article-share-link">Share</a>
            
            
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Embedded-system-programming-Kinect-OpenNI-Network/">Embedded system programming - Kinect & OpenNI - Network</a></li></ul>

          </footer>

        </div>

        
          
<nav id="article-nav" class="white">
  <div class="nav-wrapper">
    <ul class="row">
    
      <li class="col s6">
        <a href="/2013/07/25/windows_programming_model_communication/" id="article-nav-newer" class="article-nav-link-wrap grey-text text-darken-1 truncate">
          <i class="fa fa-arrow-left"></i>
          <span class="article-nav-title">windows编程_父对话框与非模态子对话框的消息通信</span>
        </a>
      </li>
    

    
      <li class="col s6">
        <a href="/2012/01/14/Windows/kinect_openNI/" id="article-nav-older" class="article-nav-link-wrap grey-text text-darken-1 right-align truncate">
          <span class="article-nav-title">OpenNI and Kinect programming</span>
          <i class="fa fa-arrow-right"></i>
        </a>
      </li>
    

    </ul>
  </div>
</nav>


        
      </article>


      



    </div>
  </div>
</div>


  



  </div>

  <footer class="page-footer grey darken-2">
    <div class="footer-copyright">
      <div class="container">
        &copy; 2018 Xiongmin Lin

        <div class="right">
          Powered by <a href="http://hexo.io/" rel="nofollow" class="white-text" target="_blank">Hexo</a>
        </div>
      </div>
    </div>
  </footer>

  <script src="/js/app.js"></script>

</body>
</html>
