<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Tag: image processing | Xiongmin Lin</title>

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <meta name="description" content="Hi, welcome to Xiongmin Lin&apos;s website">
<meta property="og:type" content="website">
<meta property="og:title" content="Xiongmin Lin">
<meta property="og:url" content="http://linxiongmin.com/blog/tags/image-processing/index.html">
<meta property="og:site_name" content="Xiongmin Lin">
<meta property="og:description" content="Hi, welcome to Xiongmin Lin&apos;s website">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Xiongmin Lin">
<meta name="twitter:description" content="Hi, welcome to Xiongmin Lin&apos;s website">

  
    <link rel="alternate" href="/atom.xml" title="Xiongmin Lin" type="application/atom+xml">
  

  
  <!--[if lte IE 10 ]><link rel="shortcut icon" href="/images/favicon.ico"><![endif]-->
  <!--[if !IE]><!-->
  <link rel="shortcut icon" href="/images/favicon.png">

  <meta name="msapplication-TileImage" content="/images/favicon.png">
  <meta name="msapplication-TileColor" content="#000000">

  <link rel="apple-touch-icon" href="/images/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/images/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/images/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/images/apple-touch-icon-144x144.png">

  <link rel="icon" sizes="256x256" href="/images/favicon.png">
  <!--<![endif]-->
  

  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro|Material+Icons|Raleway:400,300,700" rel="stylesheet" type="text/css">

  <link rel="stylesheet" href="/css/vendors.css">
  <link rel="stylesheet" href="/css/style.css">
  


  <script src="/js/vendors.js"></script>

  <script>
    define('jquery', function () {
      return window.jQuery;
    });
  </script>


</head>
<body>

  <div class="navbar-fixed">
  <nav id="main-navbar" class="grey lighten-5 z-depth-0" role="navigation">
    <div class="nav-wrapper container">

      <a id="logo-container" href="/" class="brand-logo center-align">
        <span>Xiongmin Lin</span>
        <sub></sub>
      </a>

      <ul class="right hide-on-med-and-down">
        
          <li>
            <a class="main-nav-link" href="/">Home</a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/blog">Blog</a>
          </li>
        
          <li>
            <a class="main-nav-link" href="https://www.linkedin.com/in/shelmylin">Linkedin</a>
          </li>
        
          <li>
            <a class="main-nav-link" href="https://github.com/XiongminLin">Github</a>
          </li>
        
      </ul>

      <a href="#" data-activates="nav-mobile" class="button-collapse">
        <i class="material-icons">menu</i>
      </a>
    </div>
  </nav>
</div>

<ul id="nav-mobile" class="side-nav">
  
  <li>
    <a class="main-nav-link" href="/">Home</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/blog">Blog</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="https://www.linkedin.com/in/shelmylin">Linkedin</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="https://github.com/XiongminLin">Github</a>
  </li>
  
</ul>


  <div id="main-container">
    <div class="container">
  <div class="row">
    <div class="col s12">

      
        <h2 class="header color-featured">Tag: image processing</h2>
      

      
        

      <article id="post-projects/sees" class="article article-type-post" itemscope="" itemprop="blogPost">

        <div class="article-inner">
          

          <header class="article-header">
          
              
  
    <h1 itemprop="name" class="header">
      <a class="article-title " href="/2015/07/24/projects/sees/">SEES Project with demo</a>
    </h1>
  


          

            <div class="article-meta">
              <i class="fa fa-calendar"></i>
              <time datetime="2015-07-25T04:20:00.000Z" itemprop="datePublished">Jul 24, 2015</time>
            </div>
          </header>


          <div class="article-entry " itemprop="articleBody">
            
              <h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><blockquote>
<p>According to a released report of WHO(World Health Organization) in August 2014, 285 million people are estimated to be visually impaired worldwide, 39 million of them are blind and 246 million have low vision. [1] They have encountered a lot of problems and among those problems, the most urgent one is mobility.<br>The Smart Environment Explorer Stick (SEES) [2] project has been implemented since 2013 by SMIR group of the laboratory LIMOS. It has been focusing on implementing a real-time, low-cost and energy efficient smart stick, providing VIP (Visually Impaired People) with both navigation and environmental detection function.<br>This project has presented a solution of adaptive context-aware knowledge based object recognition in SEES project. With a single camera, several fast and reliable object detecting methods have been developed, combining color based method, shape based method and feature based method together, to give a fast and reliable solution for SEES project.<br>A combined detecting method has been developed in this project to detect the door. Filtered HSV (Hue-Saturation-Value) color area and edge line of the potential objects were both considered in this combined detecting method. For other objects such as doorplate, ORB (Oriented FAST and Rotated BRIEF, FAST, Features from accelerated segment test, BRIEF, Binary Robust Independent Elementary Features) method was used for its fast and accurate performance to detect the features, which were stored in a database. A confidence value was attached to each object detected. The confidence model was also used in data fusion with other indoor navigation results that came from other sensors, such as accelerometer and wheel encoder.<br>A Multi-resolution pyramid computing algorithm was implemented in the project. According to different situation, the system would switch between different detecting methods.<br>This project has provided fast and reliable object information to SEES project and helps improve the accuracy of VIP’s indoor position.</p>
</blockquote>
<blockquote>
<p> Keywords: Visually impaired people, Indoor navigation; Object recognition; Embedded system</p>
</blockquote>
<blockquote>
<p>根据世界卫生组织 WHO 在 2014 年 8 月发布的报告,世界上有大约两亿八千五百多万人患有视力障碍。视力障碍患者在生活中会有诸多不便,其中最大的挑战在于他们的室内活动上的不方便。应对这种问题,传统的解决办法是导盲杖或是导盲犬。随着科技的进步,越来越多的技能设备或技术应用到了盲人室内导航领域,比如在传统导盲杖上安装多种传感器以辅助视力障碍者行走。现有的很多研究和实现都专注于解决导航,寻路等,很少有将单个相机和多种传感器综合起来的解决方案。</p>
</blockquote>
<blockquote>
<p>SEES 项目是一项关于智能环境导盲杖的研究,由法国 LIMOS 的 SMIR 小组于 2013 年提出。本文主要用单一摄像头解决 SEES 的环境探测问题,旨在为视力障碍患者提供一个实时、低成本及可靠的物体快速识别方案。室内重要物体的识别包括门、门把手以及门牌的识别,针对门,本文提出了一种综合检测算法,结合颜色检测及边界检测方法,不必预先建立特征数据库,只需使用简单的训练方法,获取相关阈值,即可实现快速识别的目的。针对门把手这种室内小物体,本文提出一种多精度映射算法,先在低像素图像上快速定位到门,而后进行精度切换,使用高像素图像来检测小物体。对于门牌这种需要详细识别内容的物体,本文使用 ORB 算法,提取物 体特征并预先储存到数据库,而后进行比较检测。 经过 PC 平台和 Raspberry Pi 平台上的双重试验,本文提出的识别室内物体的解决方案, 具有良好的实时性和准确性,达到了预期的目标,同时通过与系统其它模块的协作,提高 了 SEES 室内导航的可靠性,实现了辅助视力障碍患者室内活动的功能。</p>
</blockquote>
<blockquote>
<ul>
<li>关键词: 视力障碍者;室内导航;物体识别;智能导盲杖</li>
</ul>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/690aa174gw1eueh5n4cboj20eq08c0t8.jpg" alt="visually impaired people with his guide dog"><br>Visually impaired people with his guide dog.</p>
<h1 id="System-design"><a href="#System-design" class="headerlink" title="System design"></a>System design</h1><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="http://ww2.sinaimg.cn/large/690aa174gw1euehvnjgizj20mr0cl3z1.jpg" alt="system architecture"><br>  A set of thresholds and images database were generated by training model. The camera attached at the stick produced real-time images and checked if there were enough computing resources in Raspberry Pi board. If the answer was yes, the image processing of object detection would be implemented in local board. But if there was not enough computing resources, the images would be sent to the server, which was more powerful than<br>Raspberry Pi board. After detecting, the results of objects would be returned back to Raspberry Pi board through Wi-Fi.</p>
<h2 id="Multi-solution-pyramid-algorithm"><a href="#Multi-solution-pyramid-algorithm" class="headerlink" title="Multi-solution pyramid algorithm"></a>Multi-solution pyramid algorithm</h2><p>  Different type of object detection called for different level accuracy. For example, the door detection method runs in a high frequency in the whole period of the software. If it took too much computing time, the detection would be slow and it could not be real-time, just like the previous method of SEES project. In this case, the door detection called for a fast and reliable computing method and decreased the size of original image was the easiest way.<br>  For another example, door handle detection was implemented only when VIP reached his destination. The computing time was not the main problem in this detection. It demanded a higher accuracy method. In this case, after a fast detection of the door under lower-level accuracy (at a size of 40<em>30 pixels), a rough door rectangle was detected. Normally, the door rectangle contained the door handle. With the given door rectangle under low level accuracy, a new rectangle was recomputed in the original image, which was at a size of 640</em>480 pixels. After the switch of the rectangle, the matched part of the image was used as the input of the door handle detection.<br><img src="http://ww4.sinaimg.cn/large/690aa174gw1euehzbcdrnj20tz0ucjt3.jpg" alt=""></p>
<h2 id="Combined-algorithm"><a href="#Combined-algorithm" class="headerlink" title="Combined algorithm"></a>Combined algorithm</h2><p>Both color based method and shape based methods were combined to detect the object. We set door detection as an example. For a real door, its HSV color area should be larger than the threshold, and in addition, there should be a line in each edge of the area detected. The algorithm was shown in the figure.<br><img src="http://ww2.sinaimg.cn/large/690aa174gw1euei4jbedlj20cy0n0tas.jpg" alt=""></p>
<h2 id="Training-application"><a href="#Training-application" class="headerlink" title="Training application"></a>Training application</h2><p>A graphical interface was implemented in this project. The thresholds of the object detection were attached with the track bars. For door detection, there were 15 thresholds, including accuracy level, lower and upper values of HSV color space, lower and upper values of objects’ area. For door handle detection, there were 10 thresholds, including lower and upper value of HSV color space, just like door detection while the values were different. For direction detection, there were five thresholds, including lower and upper angles of the lines detected the max gap between two lines and so on.<br><img src="http://ww2.sinaimg.cn/large/690aa174gw1euei7o7838j20zp0jzq80.jpg" alt=""></p>
<h1 id="Project-results"><a href="#Project-results" class="headerlink" title="Project results"></a>Project results</h1><h2 id="Indoor-position"><a href="#Indoor-position" class="headerlink" title="Indoor position"></a>Indoor position</h2><p>The position of visually impaired people was computed by my partner Jean CONNIER<br><img src="http://ww1.sinaimg.cn/large/690aa174gw1eueii3hu0bj20ke0esmxt.jpg" alt=""></p>
<h2 id="Door-detection"><a href="#Door-detection" class="headerlink" title="Door detection"></a>Door detection</h2><p><img src="http://ww3.sinaimg.cn/large/690aa174gw1euei9kwo2cj20hs0e4adc.jpg" alt=""></p>
<p>the computing time of door detection under different resolutions.<br><img src="http://ww4.sinaimg.cn/large/690aa174gw1eueidsxyroj20g3097t9o.jpg" alt=""></p>
<h2 id="Door-handle-detection"><a href="#Door-handle-detection" class="headerlink" title="Door handle detection"></a>Door handle detection</h2><p><img src="http://ww3.sinaimg.cn/large/690aa174gw1eueia82to6j20hs0e4gnm.jpg" alt=""></p>
<h2 id="Door-plate-detection"><a href="#Door-plate-detection" class="headerlink" title="Door plate detection"></a>Door plate detection</h2><p>I implemented three feature based method to detect the doorplate, SIFT, SURF, ORB, consider the computing time and the number of matched features, i finally chose ORB.</p>
<p><img src="http://ww4.sinaimg.cn/large/690aa174gw1eueiaqzr5vj20ew0bcab5.jpg" alt="ORB feature detector"></p>
<p>The computing time of SIFT, SURF and ORB were given in the figure below.<br><img src="http://ww2.sinaimg.cn/large/690aa174gw1eueiet5wiuj209i070aan.jpg" alt="coomputing time"></p>
<h1 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h1><iframe width="640" height="390" src="https://www.youtube.com/embed/J0-jTmg6dmo" frameborder="0" allowfullscreen></iframe>

<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1]. World Health Organization, Visual impairment and blindness. <a href="http://www.who.int/mediacentre/factsheets/fs282/en/" target="_blank" rel="noopener">http://www.who.int/mediacentre/factsheets/fs282/en/</a><br>[2]. Yusro, M., K.M. Hou, E. Pissaloux, H.L. Shi, K. Ramli, and D. Sudiana. ‘SEES: Concept and Design of a Smart Environment Explorer Stick’. In 2013 The 6th International Conference on Human System Interaction (HSI), 70–77, 2013.</p>

            
          </div>

          

          <footer class="article-footer">
            <a data-url="http://linxiongmin.com/2015/07/24/projects/sees/" data-id="cjpf53rf2001ce74za8924ri4" class="article-share-link">Share</a>
            
            
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/image-processing/">image processing</a></li></ul>

          </footer>

        </div>

        
      </article>


      




      


      



    </div>
  </div>
</div>

  </div>

  <footer class="page-footer grey darken-2">
    <div class="footer-copyright">
      <div class="container">
        &copy; 2018 Xiongmin Lin

        <div class="right">
          Powered by <a href="http://hexo.io/" rel="nofollow" class="white-text" target="_blank">Hexo</a>
        </div>
      </div>
    </div>
  </footer>

  <script src="/js/app.js"></script>

</body>
</html>
